[
  {
    "id": "1809.00832v1",
    "ques": "Is throughput of inference for a batch size of 10 greater than throughput of training for batch size of 25?",
    "ans": "less than",
    "tag": "Logical operation"
  },
  {
    "id": "1809.00832v1",
    "ques": "For which dataset is the third least throughput observed and what is the value?",
    "ans": "Dataset-Moderate, Value-27.3",
    "tag": "Ordering/sorting, Selection by rank"
  },
  {
    "id": "1805.11461v1",
    "ques": "Least F1 score is observed for which representation?",
    "ans": "UD v1.3",
    "tag": "Selection by rank"
  },
  {
    "id": "1805.11461v1",
    "ques": "Which representation has the highest F1 score with default values?",
    "ans": "CoNLL08",
    "tag": "Selection by rank"
  },
  {
    "id": "1805.11461v1",
    "ques": "Which relation type gives best F1 score without sdp?",
    "ans": "USAGE",
    "tag": "Selection by rank"
  },
  {
    "id": "1805.11461v1",
    "ques": "Which relation type gives the least F1 score with sdp?",
    "ans": "COMPARE",
    "tag": "Selection by rank"
  },
  {
    "id": "1805.11461v1",
    "ques": "On which relation type does sdp show the most effect?",
    "ans": "TOPIC",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1704.06104v2",
    "ques": "Taggers or parsers, which have the lower standard deviation?",
    "ans": "Taggers",
    "tag": "Cell Selection(II), selection by rank"
  },
  {
    "id": "1704.06104v2",
    "ques": "What is the highest standard of deviation observed?",
    "ans": "±13.57",
    "tag": "Cell Selection(II), selection by rank"
  },
  {
    "id": "1704.06104v2",
    "ques": "For essay level, what is the value for LSTM-Parser?",
    "ans": "9.40±13.57",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1704.06104v2",
    "ques": "For paragraph level, what is the value for STagBL?",
    "ans": "64.74±1.97",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1911.03905v1",
    "ques": "Which part in the original dataset has SER(%)  just lower than the TRAIN part?",
    "ans": "TEST",
    "tag": "Ordering/sorting"
  },
  {
    "id": "1911.03905v1",
    "ques": "For which system is the least CIDEr value observed?",
    "ans": "SC-LSTM",
    "tag": "Selection by rank"
  },
  {
    "id": "1911.03905v1",
    "ques": "Which value, high disfluency or low disfluency, indicates better performance?",
    "ans": "Low disfluency",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1911.03905v1",
    "ques": "Which 2 types of training data have the same disfluency value?",
    "ans": "Original and Cleaned added",
    "tag": "Logical operations"
  },
  {
    "id": "1908.05957v2",
    "ques": "Which model gives the highest BLEU score and what is the value?",
    "ans": "DCGCN(ensemble), value-35.3",
    "tag": "Selection by rank"
  },
  {
    "id": "1908.05957v2",
    "ques": "How many Gigaword sentences are parsed as training data in the case of highest B score?",
    "ans": "0.3M",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1908.05957v2",
    "ques": "Which ensemble model gives the least C score?",
    "ans": "Seq2SeqB model",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1908.05957v2",
    "ques": "Which ensemble model gives the least C score for English-German translation tasks?",
    "ans": "Seq2SeqB",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1908.05957v2",
    "ques": "Which ensemble model gives the least C score for English-Czech translation tasks?",
    "ans": "GGNN2Seq",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1908.05957v2",
    "ques": "For what values of n and m is the highest BLEU score observed for one block DCGCN?",
    "ans": "n=6,m=6",
    "tag": "Selection by rank"
  },
  {
    "id": "1908.05957v2",
    "ques": "For what values of n and m is the highest BLEU score observed for two block DCGCN?",
    "ans": "n=3,m=6",
    "tag": "Selection by rank"
  },
  {
    "id": "1908.05957v2",
    "ques": "For what values of n and m is the highest C score observed for two block DCGCN and what is the value?",
    "ans": "n=6,m=3, value-53.4",
    "tag": "Selection by rank"
  },
  {
    "id": "1908.05957v2",
    "ques": "Which model has the highest C value?",
    "ans": "DCGCN4 (36)",
    "tag": "Selection by rank"
  },
  {
    "id": "1908.05957v2",
    "ques": "Which model, DCGCN(3) with 18.6M parameters or DCGCN(4) with 18.4M parameters, performs better?",
    "ans": "DCGCN(4) with 18.4M parameters",
    "tag": "Logical Operations"
  },
  {
    "id": "1908.05957v2",
    "ques": "For the DCGCN(2) model with 12.5M parameters what are the B and C values?",
    "ans": "23.8 and 53.8",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1908.05957v2",
    "ques": "For which model is the lowest C value observed?",
    "ans": "{2, 3, 4} dense blocks",
    "tag": "Selection by rank"
  },
  {
    "id": "1908.05957v2",
    "ques": "Which 2 encoder module models have the same C value?",
    "ans": "Global node and Linear combination",
    "tag": "Logical operations"
  },
  {
    "id": "1902.06423v1",
    "ques": "On which task N (0, 0.1) and our paper initialization have the same performance?",
    "ans": "SubjNum",
    "tag": "Logical operations"
  },
  {
    "id": "1902.06423v1",
    "ques": "For which initialization does the SOMO task give the highest value?",
    "ans": "N(0,0.1)",
    "tag": "Selection by rank"
  },
  {
    "id": "1902.06423v1",
    "ques": "What is the only task at which CBOW gives better performance than CMOW?",
    "ans": "Word content memorization",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1902.06423v1",
    "ques": "What are the highest TopConst and SOMO values observed?",
    "ans": "74.3 and 50.7",
    "tag": "Selection by rank"
  },
  {
    "id": "1902.06423v1",
    "ques": "On which downstream tasks does the CBOW method have the highest score?",
    "ans": "CR,MR,SICK-R",
    "tag": "Selection by rank"
  },
  {
    "id": "1902.06423v1",
    "ques": "Which model gives the best performance on SUBJ task?",
    "ans": "Hybrid",
    "tag": "Selection by rank"
  },
  {
    "id": "1902.06423v1",
    "ques": "On which downstream task do 2 methods give the same performance?",
    "ans": "MPQA",
    "tag": "Logical operations"
  },
  {
    "id": "1902.06423v1",
    "ques": "What is the relative change with respect to hybrid for CBOW model on STS13 downstream task?",
    "ans": "-8%",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1902.06423v1",
    "ques": "What is the relative change with respect to hybrid for CMOW model on STS14 downstream task?",
    "ans": "+42.4%",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1902.06423v1",
    "ques": "On which unsupervised downstream tasks does CBOW method give the best performance?",
    "ans": "STS13,STS14 and STS15",
    "tag": "Selection by rank"
  },
  {
    "id": "1902.06423v1",
    "ques": "On which task N (0, 0.1) and Glorot initialization have the same performance?",
    "ans": "SST5",
    "tag": "Logical operations"
  },
  {
    "id": "1902.06423v1",
    "ques": "What is the highest TREC score observed and for which initialization?",
    "ans": "88.4 for Glorot initialization",
    "tag": "Selection by rank"
  },
  {
    "id": "1902.06423v1",
    "ques": "On which unsupervised downstream tasks does CBOW-C and CBOW-R have the same value?",
    "ans": "STS12",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1902.06423v1",
    "ques": "For which method is the highest STS15 value observed?",
    "ans": "CBOW-C",
    "tag": "Selection by rank"
  },
  {
    "id": "1905.07189v2",
    "ques": "Under All setting highest error for LOC was observed for which system?",
    "ans": "Name matching system",
    "tag": "Selection by rank"
  },
  {
    "id": "1905.07189v2",
    "ques": "Under In E+ setting lowest error for PER was observed for which system?",
    "ans": "Supervised learning",
    "tag": "Selection by rank"
  },
  {
    "id": "1905.07189v2",
    "ques": "Under All setting highest value for R was observed for which system?",
    "ans": "Supervised learning",
    "tag": "Selection by rank"
  },
  {
    "id": "1905.07189v2",
    "ques": "What is the value of F1 under the In E+ setting for the MIL-ND(model 2) system?",
    "ans": "72.50 ±0.68",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1905.07189v2",
    "ques": "Under In E+ setting lowest value for P was observed for which system?",
    "ans": "Name matching",
    "tag": "Selection by rank"
  },
  {
    "id": "1909.00352v1",
    "ques": "Which among our models performs the best on the LDC2015E86 test dataset?",
    "ans": "G2S-GGNN model",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1909.00352v1",
    "ques": "What are the BLEU and METEOR scores achieved by the G2S-GGNN model for the LDC2017T10 test dataset?",
    "ans": "BLEU score- 27.87± 0.15, METEOR score- 33.21 ± 0.15",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1909.00352v1",
    "ques": "Models are trained on how many additional Gigaword data?",
    "ans": "200K",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1909.00352v1",
    "ques": "Which baseline model achieves the highest BLEU score?",
    "ans": "Guo et al. (2019)",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1909.00352v1",
    "ques": "What are the number of parameters used in the GEt + biLSTM model?",
    "ans": "59.6M",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1909.00352v1",
    "ques": "Which model gives the highest BLEU score?",
    "ans": "GEt + GEb + biLSTM",
    "tag": "Selection by rank"
  },
  {
    "id": "1909.00352v1",
    "ques": "Which model has the best performance for graph diameters in range 7-13?",
    "ans": "G2S-GGNN model",
    "tag": "Selection by rank"
  },
  {
    "id": "1909.00352v1",
    "ques": "As the sentence length is increasing, the performance decreases or increases?",
    "ans": "Decreases",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1909.00352v1",
    "ques": "What is the highest METEOR score observed for Max Node Out-degree of 4-8?",
    "ans": "33.1 +10.4%",
    "tag": "Selection by rank"
  },
  {
    "id": "1909.00352v1",
    "ques": "What is the highest METEOR score observed?",
    "ans": "37.9 +8.5%",
    "tag": "Selection by rank"
  },
  {
    "id": "1909.00352v1",
    "ques": "What is the least MISS value observed?",
    "ans": "GOLD",
    "tag": "Selection by rank"
  },
  {
    "id": "1909.00352v1",
    "ques": "What are the ADDED and MISS values observed for the GOLD model?",
    "ans": "50.77 and 28.35",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1801.07772v1",
    "ques": "For which language has the highest POS tagging accuracy observed?",
    "ans": "Es",
    "tag": "Selection by rank"
  },
  {
    "id": "1801.07772v1",
    "ques": "What are the POS and SEM tagging accuracy of Ru?",
    "ans": "88.6 and 85.8",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1801.07772v1",
    "ques": "What is the POS tagging accuracy for the 2nd encoding layer for Ar language?",
    "ans": "",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1801.07772v1",
    "ques": "For which encoding layer highest POS tagging accuracy for Ar language is achieved?",
    "ans": "1st layer",
    "tag": "Selection by rank"
  },
  {
    "id": "1808.06640v2",
    "ques": "What is the protected attribute for ∆ of 8.1?",
    "ans": "Gender",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1808.06640v2",
    "ques": "For PAN16 data, for which task is the highest accuracy achieved?",
    "ans": "Mention task",
    "tag": "Selection by rank"
  },
  {
    "id": "1808.06640v2",
    "ques": "Mention all the unique protected attributes?",
    "ans": "Race,gender,age",
    "tag": "Aggregate selection"
  },
  {
    "id": "1808.06640v2",
    "ques": "What are all unique tasks?",
    "ans": "sentiment, mention",
    "tag": "Aggregate selection"
  },
  {
    "id": "1905.13324v1",
    "ques": "Which model has the best performance on the WT2 language modeling task under dynamic column?",
    "ans": "LSTM",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1905.13324v1",
    "ques": "Which model has the best performance on the PTB language modeling task under finetune column?",
    "ans": "LRN",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1905.13324v1",
    "ques": "For which model is the highest test accuracy observed under +LN+BERT under time column?",
    "ans": "LSTM",
    "tag": "Cell Selection(II) and selection by rank"
  },
  {
    "id": "1905.13324v1",
    "ques": "Which model has the best performance for YelpPolar under ERR column?",
    "ans": "GRU",
    "tag": "Cell Selection(II) and selection by rank"
  },
  {
    "id": "1905.13324v1",
    "ques": "Which model takes the least time to decode one sentence measured on the newstest2014 dataset?",
    "ans": "ATR",
    "tag": "Cell Selection(II) and selection by rank"
  },
  {
    "id": "1905.13324v1",
    "ques": "What is the #Params value for the oLRN model?",
    "ans": "164M",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1905.13324v1",
    "ques": "What is the Exact match/F1-score in the results published by Wang et al. (2017) for the base model?",
    "ans": "71.1/79.5",
    "tag": "Cell Selection(II)"
  },
  {
    "id": "1905.13324v1",
    "ques": "What is the #Params value for the LRN model?",
    "ans": "2.14M",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1905.13324v1",
    "ques": "After integrating Elmo, which model gives the highest Exact match/F1-score?",
    "ans": "LRN",
    "tag": "Cell Selection(II) and selection by rank"
  },
  {
    "id": "1905.13324v1",
    "ques": "What is the Exact match/F1-score for the ATR base model?",
    "ans": "69.73/78.70",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1905.13324v1",
    "ques": "What is the #Params value for the LRN model ?",
    "ans": "129K",
    "tag": "Cell Selection(I)"
  },
  {
    "id": "1905.13324v1",
    "ques": "Which model performed better, LSTM or GRU?",
    "ans": "LSTM",
    "tag": "Cell Selection(II) and selection by rank"
  }
]