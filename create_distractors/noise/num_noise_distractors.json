[
  {
    "id": "1809.00832v1_q0",
    "ques": "What is the throughput on inference using fold\u2019s folding technique on batch size of 10?",
    "ground_truth": "52.2",
    "noise_distractor": "55.12"
  },
  {
    "id": "1809.00832v1_q1",
    "ques": "What is the highest throughput during training?",
    "ground_truth": "61.6",
    "noise_distractor": "68.7"
  },
  {
    "id": "1809.00832v1_q2",
    "ques": "What is the difference between highest and lowest throughput observed?",
    "ground_truth": "52.6",
    "noise_distractor": "53.13"
  },
  {
    "id": "1809.00832v1_q0",
    "ques": "What is the throughput using linear datasets on batch size of 10?",
    "ground_truth": "22.7",
    "noise_distractor": "24.86"
  },
  {
    "id": "1809.00832v1_q1",
    "ques": "What is the highest throughput observed?",
    "ground_truth": "129.7",
    "noise_distractor": "143.45"
  },
  {
    "id": "1809.00832v1_q3",
    "ques": "What is the sum of least and highest throughput observed?",
    "ground_truth": "137.3",
    "noise_distractor": "117.83"
  },
  {
    "id": "1805.11461v1_q0",
    "ques": "What is the F1 score obtained for SB representation with default values?",
    "ground_truth": "73.34",
    "noise_distractor": "71.38"
  },
  {
    "id": "1805.11461v1_q1",
    "ques": "What is the difference in F1 score with optimal and default values for SB representation?",
    "ground_truth": "2.22",
    "noise_distractor": "2.04"
  },
  {
    "id": "1805.11461v1_q3",
    "ques": "What is the diff value for RESULT relation type?",
    "ground_truth": "+27.23",
    "noise_distractor": "26.12"
  },
  {
    "id": "1704.06104v2_q0",
    "ques": "What is the C-F1 under 50% column for y-3:yc-1?",
    "ground_truth": "66.84",
    "noise_distractor": "65.23"
  },
  {
    "id": "1704.06104v2_q1",
    "ques": "What is the R-F1 under 100% column for y-3:yc-3?",
    "ground_truth": "30.22",
    "noise_distractor": "27.19"
  },
  {
    "id": "1704.06104v2_q2",
    "ques": "What is the highest C-F1 under 50% column observed?",
    "ground_truth": "67.84",
    "noise_distractor": "68.89"
  },
  {
    "id": "1704.06104v2_q3",
    "ques": "What is the least F1 under 100% column observed?",
    "ground_truth": "34.35",
    "noise_distractor": "38.41"
  },
  {
    "id": "1704.06104v2_q0",
    "ques": "What is the C-F1 under 50% column for paragraph level on MST-Parser?",
    "ground_truth": "6.90",
    "noise_distractor": "6.07"
  },
  {
    "id": "1704.06104v2_q1",
    "ques": "What is the R-F1 under 100% column for essay level on LSTM-ER?",
    "ground_truth": "29.56",
    "noise_distractor": "29.3"
  },
  {
    "id": "1704.06104v2_q2",
    "ques": "What is the highest C-F1 under 50% column for paragraph level observed?",
    "ground_truth": "77.19",
    "noise_distractor": "71.9"
  },
  {
    "id": "1704.06104v2_q3",
    "ques": "What is the highest F1 value for essay level observed?",
    "ground_truth": "50.51",
    "noise_distractor": "49.76"
  },
  {
    "id": "1911.03905v1_q0",
    "ques": "What is the BLEU value for the TGen- system and trained on the original dataset?",
    "ground_truth": "36.85",
    "noise_distractor": "41.17"
  },
  {
    "id": "1911.03905v1_q1",
    "ques": "What is the highest SER value observed?",
    "ground_truth": "35.03",
    "noise_distractor": "34.39"
  },
  {
    "id": "1911.03905v1_q2",
    "ques": "What is the METEOR value for the TGen+ system and trained on the cleaned missing dataset?",
    "ground_truth": "37.94",
    "noise_distractor": "43.43"
  },
  {
    "id": "1911.03905v1_q3",
    "ques": "What is the least CIDEr value observed?",
    "ground_truth": "0.3855",
    "noise_distractor": "0.39"
  },
  {
    "id": "1911.03905v1_q0",
    "ques": "What is the SER(%) for the original dataset DEV part?",
    "ground_truth": "11.42",
    "noise_distractor": "11.44"
  },
  {
    "id": "1911.03905v1_q1",
    "ques": "What is the difference of MRs in the cleaned and original dataset?",
    "ground_truth": "3500",
    "noise_distractor": "3738.23"
  },
  {
    "id": "1911.03905v1_q2",
    "ques": "What is the highest SER(%) obtained?",
    "ground_truth": "17.69",
    "noise_distractor": "18.28"
  },
  {
    "id": "1911.03905v1_q0",
    "ques": "What is the BLEU value for the TGen- system and trained on the original dataset?",
    "ground_truth": "63.37",
    "noise_distractor": "63.16"
  },
  {
    "id": "1911.03905v1_q1",
    "ques": "What is the highest SER value observed?",
    "ground_truth": "31.51",
    "noise_distractor": "30.55"
  },
  {
    "id": "1911.03905v1_q2",
    "ques": "What is the METEOR value for the TGen+ system and trained on the cleaned missing dataset?",
    "ground_truth": "44.84",
    "noise_distractor": "46.13"
  },
  {
    "id": "1911.03905v1_q0",
    "ques": "What is the disfluency for original training data?",
    "ground_truth": "14",
    "noise_distractor": "14.74"
  },
  {
    "id": "1911.03905v1_q2",
    "ques": "What is the difference between disfluency values of cleaned added and cleaned training data?",
    "ground_truth": "9",
    "noise_distractor": "10.8"
  },
  {
    "id": "1908.05957v2_q0",
    "ques": "What is the BLEU score of the DCGCN ensemble model without external data?",
    "ground_truth": "28.2",
    "noise_distractor": "26.37"
  },
  {
    "id": "1908.05957v2_q1",
    "ques": "What is the BLEU score of the DCGCN single model trained with 0.1M extra parameters?",
    "ground_truth": "29.0",
    "noise_distractor": "27.16"
  },
  {
    "id": "1908.05957v2_q0",
    "ques": "What is the C score of the single Seq2SeqB model?",
    "ground_truth": "49.1",
    "noise_distractor": "50.44"
  },
  {
    "id": "1908.05957v2_q2",
    "ques": "What is the difference between the C score of our ensemble model and GGNN2Seq ensemble model?",
    "ground_truth": "6.1",
    "noise_distractor": "5.58"
  },
  {
    "id": "1908.05957v2_q3",
    "ques": "What is the B score of the single DCGCN model?",
    "ground_truth": "27.9",
    "noise_distractor": "24.81"
  },
  {
    "id": "1908.05957v2_q0",
    "ques": "What is the B score of the single BoW+GCN model for English-German translation tasks?",
    "ground_truth": "12.2",
    "noise_distractor": "11.51"
  },
  {
    "id": "1908.05957v2_q3",
    "ques": "What is the difference of BLEU points between the best single GCN based model and our single model for EnCs task?",
    "ground_truth": "2.5",
    "noise_distractor": "2.94"
  },
  {
    "id": "1908.05957v2_q0",
    "ques": "What is the BLEU value for one block DCGCN n=1,m=2",
    "ground_truth": "19.2",
    "noise_distractor": "18.87"
  },
  {
    "id": "1908.05957v2_q0",
    "ques": "How many layered GCN+RC+LA gives the highest BLEU score?",
    "ground_truth": "9",
    "noise_distractor": "9.09"
  },
  {
    "id": "1908.05957v2_q1",
    "ques": "How many layered GCN+RC+LA gives the highest C score?",
    "ground_truth": "10",
    "noise_distractor": "9.08"
  },
  {
    "id": "1908.05957v2_q2",
    "ques": "What is the BLEU score of the GCN+RC(6) model?",
    "ground_truth": "19.9",
    "noise_distractor": "21.73"
  },
  {
    "id": "1908.05957v2_q1",
    "ques": "What is the difference of BLEU scores of above models?",
    "ground_truth": "1",
    "noise_distractor": "0.93"
  },
  {
    "id": "1908.05957v2_q2",
    "ques": "What is the highest C value observed?",
    "ground_truth": "55.4",
    "noise_distractor": "54.13"
  },
  {
    "id": "1908.05957v2_q0",
    "ques": "What is the BLEU value for the DCGCN4 model?",
    "ground_truth": "25.5",
    "noise_distractor": "24.33"
  },
  {
    "id": "1908.05957v2_q1",
    "ques": "Removing dense connections in 3rd and 4th block results in what C value?",
    "ground_truth": "54.1",
    "noise_distractor": "50.31"
  },
  {
    "id": "1908.05957v2_q3",
    "ques": "What is the difference in C score of the DCGCN4 model and the -{4} dense block model?",
    "ground_truth": "0.5",
    "noise_distractor": "0.41"
  },
  {
    "id": "1908.05957v2_q0",
    "ques": "What is the BLEU score for encoder modules linear combination?",
    "ground_truth": "23.7",
    "noise_distractor": "24.77"
  },
  {
    "id": "1908.05957v2_q1",
    "ques": "What is the C value for Decoder modules coverage mechanism?",
    "ground_truth": "53.0",
    "noise_distractor": "52.09"
  },
  {
    "id": "1908.05957v2_q2",
    "ques": "What is the highest C value observed?",
    "ground_truth": "55.4",
    "noise_distractor": "51.36"
  },
  {
    "id": "1902.06423v1_q0",
    "ques": "What is the WC value for Glorot initialization?",
    "ground_truth": "57.0",
    "noise_distractor": "55.74"
  },
  {
    "id": "1902.06423v1_q1",
    "ques": "On how many tasks does Glorot initialization have highest performance?",
    "ground_truth": "2",
    "noise_distractor": "2.16"
  },
  {
    "id": "1902.06423v1_q0",
    "ques": "What is the WC value for H-CMOW method for 400 dimensional word embedding?",
    "ground_truth": "38.2",
    "noise_distractor": "37.03"
  },
  {
    "id": "1902.06423v1_q2",
    "ques": "What is the highest WC value observed?",
    "ground_truth": "89.5",
    "noise_distractor": "91.64"
  },
  {
    "id": "1902.06423v1_q0",
    "ques": "What is the SICK-R value for CMOW method for 784 dimensional word embedding?",
    "ground_truth": "76.2",
    "noise_distractor": "66.6"
  },
  {
    "id": "1902.06423v1_q0",
    "ques": "What is the STS16 score for the CMOW model?",
    "ground_truth": "52.2",
    "noise_distractor": "39.65"
  },
  {
    "id": "1902.06423v1_q0",
    "ques": "What is the SICK-R value for Glorot initialization?",
    "ground_truth": "73.6",
    "noise_distractor": "69.05"
  },
  {
    "id": "1902.06423v1_q1",
    "ques": "On how many tasks does our paper initialization have highest performance?",
    "ground_truth": "7",
    "noise_distractor": "7.22"
  },
  {
    "id": "1902.06423v1_q0",
    "ques": "What is the STS16 value for the CMOW-C method?",
    "ground_truth": "41.6",
    "noise_distractor": "40.9"
  },
  {
    "id": "1902.06423v1_q2",
    "ques": "What is the value observed in the above question?",
    "ground_truth": "43.5",
    "noise_distractor": "50.94"
  },
  {
    "id": "1902.06423v1_q0",
    "ques": "What is the WC value for CMOW-R method?",
    "ground_truth": "72.9",
    "noise_distractor": "74.63"
  },
  {
    "id": "1902.06423v1_q1",
    "ques": "What is the highest SOMO value observed?",
    "ground_truth": "50.7",
    "noise_distractor": "46.78"
  },
  {
    "id": "1902.06423v1_q2",
    "ques": "On how many linguistic probing tasks does CMOW-C perform better than CMOW-R?",
    "ground_truth": "2",
    "noise_distractor": "1.69"
  },
  {
    "id": "1902.06423v1_q3",
    "ques": "On how many linguistic probing tasks does CBOW-R perform better than CBOW-C?",
    "ground_truth": "3",
    "noise_distractor": "3.25"
  },
  {
    "id": "1902.06423v1_q0",
    "ques": "What is the SICK-E value for the CMOW-R method?",
    "ground_truth": "77.2",
    "noise_distractor": "73.17"
  },
  {
    "id": "1902.06423v1_q1",
    "ques": "What is the highest MPQA value observed?",
    "ground_truth": "87.5",
    "noise_distractor": "81.33"
  },
  {
    "id": "1902.06423v1_q2",
    "ques": "On how many supervised downstream tasks does CMOW-C perform better than CMOW-R?",
    "ground_truth": "1",
    "noise_distractor": "0.74"
  },
  {
    "id": "1902.06423v1_q3",
    "ques": "On how many supervised downstream tasks does CBOW-R perform better than CBOW-C?",
    "ground_truth": "5",
    "noise_distractor": "4.8"
  },
  {
    "id": "1905.07189v2_q0",
    "ques": "What is the value of MISC under the In E+ setting for MIL system?",
    "ground_truth": "53.61",
    "noise_distractor": "43.88"
  },
  {
    "id": "1905.07189v2_q2",
    "ques": "What is the value of ORG under the All setting for the MIL-ND system?",
    "ground_truth": "77.15",
    "noise_distractor": "73.97"
  },
  {
    "id": "1905.07189v2_q0",
    "ques": "What is the value of R under the In E+ setting for the MIL(model 1) system?",
    "ground_truth": "69.38",
    "noise_distractor": "60.63"
  },
  {
    "id": "1909.00352v1_q0",
    "ques": "When the premise is generated, what is the CON value for the S2S model?",
    "ground_truth": "11.17",
    "noise_distractor": "10.28"
  },
  {
    "id": "1909.00352v1_q1",
    "ques": "For GEN->REF, what is the ENT value for the G2S-GIN model?",
    "ground_truth": "76.27",
    "noise_distractor": "67.34"
  },
  {
    "id": "1909.00352v1_q2",
    "ques": "When the hypothesis is generated, what is the NEU value for the G2S-GAT model?",
    "ground_truth": "13.92",
    "noise_distractor": "13.25"
  },
  {
    "id": "1909.00352v1_q3",
    "ques": "What is the lowest contradiction average percentage, when premise is generated?",
    "ground_truth": "8.09",
    "noise_distractor": "8.38"
  },
  {
    "id": "1909.00352v1_q0",
    "ques": "What is the BLEU score for the test set of LDC2015E86 on Cao et al. model?",
    "ground_truth": "23.5",
    "noise_distractor": "21.15"
  },
  {
    "id": "1909.00352v1_q1",
    "ques": "What is the METEOR score for the test set of LDC2015E86 on the Damonte et al. model?",
    "ground_truth": "23.6",
    "noise_distractor": "22.23"
  },
  {
    "id": "1909.00352v1_q0",
    "ques": "What is the BLEU score for Konstas et al. model?",
    "ground_truth": "27.4",
    "noise_distractor": "21.07"
  },
  {
    "id": "1909.00352v1_q3",
    "ques": "What is the BLEU score achieved by our model?",
    "ground_truth": "32.23",
    "noise_distractor": "34.66"
  },
  {
    "id": "1909.00352v1_q0",
    "ques": "What is the BLEU score for biLSTM model?",
    "ground_truth": "22.50",
    "noise_distractor": "25.52"
  },
  {
    "id": "1909.00352v1_q3",
    "ques": "What is the least METEOR score observed?",
    "ground_truth": "30.42",
    "noise_distractor": "29.69"
  },
  {
    "id": "1909.00352v1_q0",
    "ques": "What is the MISS value for the S2S model?",
    "ground_truth": "37.14",
    "noise_distractor": "32.32"
  },
  {
    "id": "1909.00352v1_q3",
    "ques": "What is the highest ADDED value observed?",
    "ground_truth": "50.77",
    "noise_distractor": "50.8"
  },
  {
    "id": "1801.07772v1_q0",
    "ques": "What is the POS tagging accuracy for Ar language?",
    "ground_truth": "88.7",
    "noise_distractor": "93.38"
  },
  {
    "id": "1801.07772v1_q1",
    "ques": "What is the SEM tagging accuracy for Es language?",
    "ground_truth": "86.1",
    "noise_distractor": "74.39"
  },
  {
    "id": "1801.07772v1_q0",
    "ques": "What is the POS tagging accuracy for MFT?",
    "ground_truth": "91.95",
    "noise_distractor": "91.79"
  },
  {
    "id": "1801.07772v1_q1",
    "ques": "What is the SEM tagging accuracy for a classifier using unsupervised word embeddings?",
    "ground_truth": "81.11",
    "noise_distractor": "94.83"
  },
  {
    "id": "1801.07772v1_q2",
    "ques": "What is the POS tagging accuracy for a classifier using upper bound encoder-decoder?",
    "ground_truth": "95.55",
    "noise_distractor": "86.1"
  },
  {
    "id": "1801.07772v1_q3",
    "ques": "What is the least POS tagging accuracy observed?",
    "ground_truth": "87.06",
    "noise_distractor": "73.02"
  },
  {
    "id": "1801.07772v1_q2",
    "ques": "What is the highest SEM tagging accuracy for the En language?",
    "ground_truth": "84.5",
    "noise_distractor": "93.85"
  },
  {
    "id": "1801.07772v1_q3",
    "ques": "What is the SEM tagging accuracy for the 3rd encoding layer for Zh language?",
    "ground_truth": "87.3",
    "noise_distractor": "89.68"
  },
  {
    "id": "1801.07772v1_q0",
    "ques": "What is the POS tagging accuracy for 2nd layer Unidirectional NMT encoder?",
    "ground_truth": "91.7",
    "noise_distractor": "92.43"
  },
  {
    "id": "1801.07772v1_q1",
    "ques": "What is the highest POS tagging accuracy in Bidirectional NMT encoder?",
    "ground_truth": "93.3",
    "noise_distractor": "96.25"
  },
  {
    "id": "1801.07772v1_q2",
    "ques": "What is the highest SEM tagging accuracy in Residual NMT encoder?",
    "ground_truth": "88.5",
    "noise_distractor": "80.94"
  },
  {
    "id": "1801.07772v1_q3",
    "ques": "What is the SEM value under column name 3 for row name Bi?",
    "ground_truth": "91.9",
    "noise_distractor": "83.61"
  },
  {
    "id": "1808.06640v2_q0",
    "ques": "What is the difference between the attacker score and the corresponding adversary\u2019s accuracy for DIAL data sentiment Task?",
    "ground_truth": "12.2",
    "noise_distractor": "9.75"
  },
  {
    "id": "1808.06640v2_q2",
    "ques": "For PAN16 data, mention task, what is the highest \u2206?",
    "ground_truth": "9.7",
    "noise_distractor": "9.92"
  },
  {
    "id": "1808.06640v2_q3",
    "ques": "Mention how many unique protected attributes are there in DIAL data?",
    "ground_truth": "1",
    "noise_distractor": "0.99"
  },
  {
    "id": "1808.06640v2_q0",
    "ques": "For DIAL data, sentiment task what is the accuracy achieved?",
    "ground_truth": "67.4",
    "noise_distractor": "62.97"
  },
  {
    "id": "1808.06640v2_q1",
    "ques": "For DIAL data what is the highest accuracy achieved?",
    "ground_truth": "83.9",
    "noise_distractor": "74.79"
  },
  {
    "id": "1808.06640v2_q2",
    "ques": "For the PAN16 data, age task what is the accuracy achieved?",
    "ground_truth": "64.8",
    "noise_distractor": "68.09"
  },
  {
    "id": "1808.06640v2_q0",
    "ques": "For DIAL data what is the balanced task acc?",
    "ground_truth": "67.4",
    "noise_distractor": "59.31"
  },
  {
    "id": "1808.06640v2_q1",
    "ques": "For PAN16 data what is the unbalanced leakage for the protected attribute age?",
    "ground_truth": "59.7",
    "noise_distractor": "65.37"
  },
  {
    "id": "1808.06640v2_q3",
    "ques": "What is the highest unbalanced task acc value?",
    "ground_truth": "86.0",
    "noise_distractor": "90.4"
  },
  {
    "id": "1808.06640v2_q0",
    "ques": "What is the highest difference between the attacker score and the corresponding adversary\u2019s accuracy?",
    "ground_truth": "9.2",
    "noise_distractor": "8.32"
  },
  {
    "id": "1808.06640v2_q1",
    "ques": "What is the least task acc value observed?",
    "ground_truth": "64.7",
    "noise_distractor": "50.87"
  },
  {
    "id": "1808.06640v2_q3",
    "ques": "What is the leakage value for mention task under DIAL data?",
    "ground_truth": "63.1",
    "noise_distractor": "55.5"
  },
  {
    "id": "1808.06640v2_q0",
    "ques": "What is the value of RNN row and guarded embedding column?",
    "ground_truth": "67.8",
    "noise_distractor": "59.73"
  },
  {
    "id": "1808.06640v2_q1",
    "ques": "Under leaky column what is the highest value?",
    "ground_truth": "64.5",
    "noise_distractor": "55.18"
  },
  {
    "id": "1808.06640v2_q2",
    "ques": "What is the sum of all values in the table?",
    "ground_truth": "246.4",
    "noise_distractor": "207.34"
  },
  {
    "id": "1905.13324v1_q0",
    "ques": "What is the test perplexity on the PTB language modeling task under finetune column for ATR model?",
    "ground_truth": "65.86",
    "noise_distractor": "69.45"
  },
  {
    "id": "1905.13324v1_q1",
    "ques": "What is the test perplexity on the WT2 language modeling task under dynamic column for SRU model?",
    "ground_truth": "57.97",
    "noise_distractor": "72.26"
  },
  {
    "id": "1905.13324v1_q0",
    "ques": "What is the test accuracy for the layer normalization model, under the time column for GRU?",
    "ground_truth": "0.419",
    "noise_distractor": "0.51"
  },
  {
    "id": "1905.13324v1_q1",
    "ques": "What is the test accuracy for the BERT model, under the ACC column for SRU?",
    "ground_truth": "89.98",
    "noise_distractor": "91.84"
  },
  {
    "id": "1905.13324v1_q2",
    "ques": "What is the highest test accuracy for the base model under the ACC column?",
    "ground_truth": "85.71",
    "noise_distractor": "96.05"
  },
  {
    "id": "1905.13324v1_q0",
    "ques": "What is the test error for the AmaPolar model, under the time column for GRU?",
    "ground_truth": "0.948",
    "noise_distractor": "0.95"
  },
  {
    "id": "1905.13324v1_q1",
    "ques": "What is the test error for the AmaFull model, under the ERR column for ATR?",
    "ground_truth": "38.54",
    "noise_distractor": "34.31"
  },
  {
    "id": "1905.13324v1_q2",
    "ques": "What is the least test error for the Yahoo model under the ERR column?",
    "ground_truth": "24.62",
    "noise_distractor": "25.46"
  },
  {
    "id": "1905.13324v1_q1",
    "ques": "What is the BLEU score for the GRU model?",
    "ground_truth": "26.28",
    "noise_distractor": "28.26"
  },
  {
    "id": "1905.13324v1_q2",
    "ques": "What is the least time per training batch measured from 0.2k training steps on Tesla P100?",
    "ground_truth": "0.99",
    "noise_distractor": "0.92"
  },
  {
    "id": "1905.13324v1_q0",
    "ques": "What is the F1 score achieved for the SRU model?",
    "ground_truth": "88.89",
    "noise_distractor": "103.28"
  },
  {
    "id": "1905.13324v1_q3",
    "ques": "What is the F1 score reported by Lample et al., 2016?",
    "ground_truth": "90.94",
    "noise_distractor": "105.89"
  }
]